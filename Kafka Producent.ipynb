{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f1864a-d95e-471d-b4dc-6a3fb9d4c70e",
   "metadata": {},
   "source": [
    "# Wersja z dostępem do środowiska\n",
    "\n",
    "Tą wersję można przejść również posiadając nowy obraz dockerowy i uruchomiony docker desktop na własnym komputerze.\n",
    "\n",
    "1. Przejdź do przeglądarki i uruchom stronę ze środowiskiem (w przypadku Docker uruchom `localhost:8888`).\n",
    "2. Uruchom (w jupyter lab za pomocą ikony terminala) nowy terminal\n",
    "\n",
    "3. Przejdź do katalogu głównego i wypisz listę wszystkich elementów. Sprawdź czy na liście znajduje się katalog `kafka`.\n",
    "\n",
    "   ```bash\n",
    "   cd ~\n",
    "   ls -all\n",
    "   ```\n",
    "4. Uruchom polecenie sprawdzające listę topiców serwera Kafki\n",
    "    ```bash\n",
    "    kafka/bin/kafka-topics.sh --list --bootstrap-server broker:9092\n",
    "    ```\n",
    "5. Dodaj topic o nazwie streaming\n",
    "   ```bash\n",
    "   kafka/bin/kafka-topics.sh --bootstrap-server broker:9092 --create --topic streaming\n",
    "   ```\n",
    "6. Sprawdź listę tematów ponownie upewniając się, że posiadasz temat `streaming`\n",
    "7. Uruchom nowy terminal na notatniku i utwórz producenta w konsoli generującego dane do nowego topicu\n",
    "```bash\n",
    "kafka/bin/kafka-console-producer.sh --bootstrap-server broker:9092 --topic streaming\n",
    "```\n",
    "\n",
    "Aby sprawdzić czy wysyłanie wiadomości działa uruchom kolejne okno terminala i wpisz następującą komendę realizującą konsumenta w konsoli: \n",
    "\n",
    "```bash\n",
    "kafka/bin/kafka-console-consumer.sh --bootstrap-server broker:9092 --topic streaming --from-beginning\n",
    "```\n",
    "> Pamiętaj aby uruchamiać komendy z odpowiedniego katalogu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "002b35b4-e5f9-42d3-b1d5-b4af337fc4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stream_stock.py\n"
     ]
    }
   ],
   "source": [
    "%%file stream_stock.py\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from time import sleep\n",
    "import random\n",
    "import yfinance as yf\n",
    "\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "def fetch_stock_data():\n",
    "    with open('/home/jovyan/notebooks/stock_indexes.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            symbol = line.strip()\n",
    "            stock = yf.Ticker(symbol)\n",
    "            try:\n",
    "                stock_info = stock.info\n",
    "                if stock_info:\n",
    "                    message = {'type': 'Stock',\n",
    "                               \"date\": datetime.now().isoformat(),\n",
    "                               'symbol': stock_info.get('symbol', 'No Data'),\n",
    "                               'currentPrice': stock_info.get('currentPrice', 'No Data'),\n",
    "                               'open': stock_info.get('open', 'No Data'),\n",
    "                               'previousClose': stock_info.get('previousClose', 'No Data'),\n",
    "                               'dayLow': stock_info.get('dayLow', 'No Data'),\n",
    "                               'dayHigh': stock_info.get('dayHigh', 'No Data'),\n",
    "                               'recommendation': stock_info.get('recommendationKey', 'No Data'),\n",
    "                               \n",
    "                               'targetHighPrice': stock_info.get('targetHighPrice', 'No Data'),\n",
    "                               'targetLowPrice': stock_info.get('targetLowPrice', 'No Data'),\n",
    "                               'targetMeanPrice': stock_info.get('targetMeanPrice', 'No Data'),\n",
    "                               'targetMedianPrice': stock_info.get('targetMedianPrice', 'No Data'),\n",
    "                               'recommendationMean': stock_info.get('recommendationMean', 'No Data'),\n",
    "                               \n",
    "                               'totalRevenue': stock_info.get('totalRevenue', 'No Data'),\n",
    "                               'revenuePerShare': stock_info.get('revenuePerShare', 'No Data'),\n",
    "                               'totalDebt': stock_info.get('totalDebt', 'No Data'),\n",
    "                               'debtToEquity': stock_info.get('debtToEquity', 'No Data'),\n",
    "                               'totalCash': stock_info.get('totalCash', 'No Data'),\n",
    "                               'totalCashPerShare': stock_info.get('totalCashPerShare', 'No Data'),\n",
    "                               'ebitda': stock_info.get('ebitda', 'No Data'),\n",
    "                               'earningsGrowth': stock_info.get('earningsGrowth', 'No Data'),\n",
    "                               'revenueGrowth': stock_info.get('revenueGrowth', 'No Data')\n",
    "                              }\n",
    "                    yield message\n",
    "                else:\n",
    "                    print(\"No data for symbol:\", symbol)\n",
    "            except:\n",
    "                print(\"Errorfor symbol\", symbol)\n",
    "\n",
    "        sleep(10)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    SERVER = \"broker:9092\"\n",
    "\n",
    "    stock_producer = KafkaProducer(\n",
    "        bootstrap_servers=[SERVER],\n",
    "        value_serializer=lambda x: json.dumps(x).encode(\"utf-8\"),\n",
    "        api_version=(3, 7, 0),)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            for stock_data in fetch_stock_data():\n",
    "                stock_producer.send(\"stock\", value=stock_data)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        stock_producer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dcffa8a-7dcc-41e9-8a58-edcb6942718e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stream_crypto.py\n"
     ]
    }
   ],
   "source": [
    "%%file stream_crypto.py\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from time import sleep\n",
    "import random\n",
    "import yfinance as yf\n",
    "\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "def fetch_crypto_data():\n",
    "    with open('/home/jovyan/notebooks/crypto_index.txt', 'r') as file:\n",
    "        ids = file.readlines()\n",
    "        ids = [id.strip() for id in ids]\n",
    "    \n",
    "    for id in ids:\n",
    "        url = f\"https://api.coingecko.com/api/v3/coins/markets?ids={id}&vs_currency=usd\"\n",
    "    \n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"x-cg-demo-api-key\": \"CG-4zHc6u3aAS8gNQbRbR5ruUPb\"\n",
    "        }\n",
    "    \n",
    "        response = requests.get(url, headers=headers)\n",
    "    \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                entry = {\n",
    "                    \"type\": \"Crypto\",\n",
    "                    \"date\": datetime.now().isoformat(), \n",
    "                    \"name\": data[0][\"name\"],\n",
    "                    \"current_price\": data[0][\"current_price\"],\n",
    "                    \"high_24h\": data[0][\"high_24h\"],\n",
    "                    \"low_24h\": data[0][\"low_24h\"],\n",
    "                    \"price_change_24h\": data[0][\"price_change_24h\"],\n",
    "                    \"price_change_percentage_24h\": data[0][\"price_change_percentage_24h\"],\n",
    "                    \"market_cap\": data[0][\"market_cap\"],\n",
    "                    \"total_volume\": data[0][\"total_volume\"],\n",
    "                    \"ath\": data[0][\"ath\"],\n",
    "                    \"atl\": data[0][\"atl\"]\n",
    "                }\n",
    "                yield entry\n",
    "            else:\n",
    "                print(f\"No data for ID: {id}\")\n",
    "        else:\n",
    "            print(f\"Error for ID: {id} code: {response.status_code}\")\n",
    "\n",
    "    sleep(10)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    SERVER = \"broker:9092\"\n",
    "    \n",
    "    crypto_producer = KafkaProducer(\n",
    "        bootstrap_servers=[SERVER],\n",
    "        value_serializer=lambda x: json.dumps(x).encode(\"utf-8\"),\n",
    "        api_version=(3, 7, 0),)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            \n",
    "            for crypto_data in fetch_crypto_data():\n",
    "                crypto_producer.send(\"crypto\", value=crypto_data)\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        crypto_producer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd228f-53a3-41db-8304-42c21b0ebf99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
